{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('//share.ipp-hgw.mpg.de/documents/pih/Documents/git/QSB_Bolometry/libprad')\n",
    "loc = '//share.ipp-hgw.mpg.de/documents/pih/Documents/git/QSB_Bolometry/results/COMBINATIONS/'\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import itertools\n",
    "import requests\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logbook_api\n",
    "import webapi_access as api\n",
    "import dat_lists as lists\n",
    "import radiational_fraction as radfrac\n",
    "import tomogram_metrics as tm\n",
    "import training as training\n",
    "import correlation as corr\n",
    "import sensitivity as sense\n",
    "import training_plot as tpl\n",
    "import plot_funcs as pf\n",
    "import prad_calculation as prad_calc\n",
    "import mClass\n",
    "\n",
    "import matplotlib.pyplot as p\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "\n",
    "import training\n",
    "import sensitivity\n",
    "import correlation\n",
    "import training_plot\n",
    "\n",
    "info = lists.geom_dat_to_json()\n",
    "vbc_list = info['channels']['eChannels']['VBC']\n",
    "hbc_list = info['channels']['eChannels']['HBCm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = lists.geom_dat_to_json()\n",
    "\n",
    "dirs = next(os.walk(loc))[1]\n",
    "# dirs.remove('bak')\n",
    "dirs.remove('old')\n",
    "\n",
    "methods = next(os.walk(loc + dirs[0] + '/'))[1][::-1]\n",
    "combs = next(os.walk(loc + dirs[0] +\n",
    "             '/' + methods[0] + '/'))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(training)\r\n",
    "importlib.reload(sensitivity)\r\n",
    "importlib.reload(correlation)\r\n",
    "importlib.reload(training_plot)\r\n",
    "\r\n",
    "foo = training.training_master(\r\n",
    "    program='20181010.032',\r\n",
    "    URI_vers='V4', mode='weighted_deviation',\r\n",
    "    nCH=3, saving=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "combinations: 100%|██████████| 1/1 [00:11<00:00, 11.59s/it]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pf)\r\n",
    "importlib.reload(corr)\r\n",
    "importlib.reload(sense)\r\n",
    "importlib.reload(tpl)\r\n",
    "importlib.reload(prad_calc)\r\n",
    "importlib.reload(mClass)\r\n",
    "\r\n",
    "base_URI = 'http://archive-webapi.ipp-hgw.mpg.de/'\r\n",
    "dat_URI = base_URI + 'Test/raw/W7XAnalysis/QSB_Bolometry/'\r\n",
    "loc = '//share.ipp-hgw.mpg.de/documents/pih/Documents/git/QSB_Bolometry/results/COMBINATIONS/'\r\n",
    "\r\n",
    "iterator = list(itertools.product(\r\n",
    "    ['20181010.032'],\r\n",
    "    ['self_correlation'],\r\n",
    "    ['3_HBCm']))\r\n",
    "#     methods, combs))  # dirs, ['coherence_fft'], combs))[:1]  \r\n",
    "\r\n",
    "for i in tqdm(range(len(iterator)), desc='combinations'):\r\n",
    "    entry = iterator[i]\r\n",
    "    # for i, entry in enumerate(iterator):\r\n",
    "    xpid, method, comb = entry\r\n",
    "    if i == 0:\r\n",
    "        xpid_old = xpid\r\n",
    "        # print('\\\\\\ ', xpid, end=' ')\r\n",
    "\r\n",
    "    if True:  # try:\r\n",
    "        # load file of comb and method for xpid\r\n",
    "        # print('>> loading file:', method, comb)\r\n",
    "        file = loc + xpid + '/' + method + \\\r\n",
    "            '/' + comb + '/spectrum_analysis_' + method + '.json'\r\n",
    "        with open(file, 'r') as f:\r\n",
    "            training_results = json.load(f)\r\n",
    "        f.close()\r\n",
    "\r\n",
    "        N = training_results['combination']\r\n",
    "        # best/worst combination/cells\r\n",
    "        ind = np.argmax(training_results['correlation'])\r\n",
    "        best_comb = training_results['combinations'][ind]  # best single combination\r\n",
    "        ind = np.argmin(training_results['correlation'])\r\n",
    "        worst_comb = training_results['combinations'][ind]  # worst single combination\r\n",
    "\r\n",
    "        best_cell = np.argsort(np.nan_to_num(training_results['av_sense_channels']))[-N:]\r\n",
    "        best1 = [training_results['av_sense_channels'][i]\r\n",
    "                for i in best_cell]  # best indiv. channels by hits\r\n",
    "        worst_cell = np.argsort(training_results['av_sense_channels'])[:N]\r\n",
    "        worst = [training_results['av_sense_channels'][i]\r\n",
    "                for i in worst_cell]  # worst indiv. channels by hits\r\n",
    "\r\n",
    "        best_cell2 = np.argsort(np.nan_to_num(training_results['av_sense_combination']))[-N:]\r\n",
    "        best2 = [training_results['av_sense_combination'][i]\r\n",
    "                for i in best_cell2]  # best indiv. channels by combinations\r\n",
    "        arr = np.array(training_results['av_sense_combination']).astype('float')\r\n",
    "        arr[arr == .0] = np.nan\r\n",
    "        worst_cell2 = np.argsort(arr)[:N]\r\n",
    "        worst2 = [arr[i] for i in worst_cell2]  # worst indiv. channels by combinations\r\n",
    "\r\n",
    "        # stuff to do once per experiment\r\n",
    "        if i == 0 or xpid_old != xpid:\r\n",
    "            # print('\\t\\\\\\ download data ...')\r\n",
    "            dat = {}\r\n",
    "            program_info = api.xpid_info(program=xpid)[0]\r\n",
    "            dat['BoloSignal'] = api.download_single(\r\n",
    "                data_req=dat_URI + 'BoloAdjusted_DATASTREAM/V4/',\r\n",
    "                program_info=program_info, debug=False)\r\n",
    "            dat['P_rad_hbc'] = api.download_single(\r\n",
    "                data_req=dat_URI + 'PradHBCm_DATASTREAM/V4/0/PradHBCm/',\r\n",
    "                program_info=program_info, debug=False)\r\n",
    "            dat['power'] = api.download_single(\r\n",
    "                data_req=dat_URI + 'PradChannels_DATASTREAM/V4/',\r\n",
    "                program_info=program_info, debug=False)\r\n",
    "\r\n",
    "            # print('\\t\\\\\\ priority data')\r\n",
    "            prio, status = api.do_before_running(\r\n",
    "                program_info=program_info, program=xpid,\r\n",
    "                date=xpid[0:8], data_object=dat)\r\n",
    "            # need stop and start indices\r\n",
    "            t_1, t_2 = (prio['t0'] + 1e8), (prio['t4'] - 1e8)\r\n",
    "            ix_s = mClass.find_nearest(np.array(\r\n",
    "                dat['BoloSignal']['dimensions']), t_1)[0]\r\n",
    "            ix_t = mClass.find_nearest(np.array(\r\n",
    "                dat['BoloSignal']['dimensions']), t_2)[0]\r\n",
    "            if i == 0:\r\n",
    "                broken_channels = prio['geometry']['channels']['droplist']\r\n",
    "            \r\n",
    "            # print('\\t\\\\\\ default values')\r\n",
    "            alpha, phi, beta = corr.default_correlation(\r\n",
    "                method=method,\r\n",
    "                arr1=dat['P_rad_hbc']['values'],\r\n",
    "                arr2=dat['P_rad_hbc']['values'],\r\n",
    "                id_1=ix_s, id_2=ix_t,\r\n",
    "                time_raw=dat['BoloSignal']['dimensions'])\r\n",
    "            # print('\\t\\\\\\ calculate for program')\r\n",
    "\r\n",
    "        for combination, name in zip(  # different N channel combinations\r\n",
    "                [best_cell, best_comb],  # worst_comb, worst_cell, best_cell2, worst_cell2],\r\n",
    "                ['best_chans', 'best_comb'  # , 'worst_comb', 'worst_chans',\r\n",
    "                # 'best_chans_comb', 'worst_chans_comb'\r\n",
    "                ]):\r\n",
    "            calculation, volume_sum = prad_calc.calculate_prad(\r\n",
    "                power=np.array(dat['power']['values'], dtype=np.float),\r\n",
    "                volume=prio['geometry']['geometry']['vbolo'],\r\n",
    "                k_bolo=prio['geometry']['geometry']['kbolo'],\r\n",
    "                volume_torus=prio['volume_torus'],\r\n",
    "                channels=combination,\r\n",
    "                camera_list=combination,\r\n",
    "                date=int(xpid[0:8]),\r\n",
    "                shotno=int(xpid[-3:]),\r\n",
    "                brk_chan=broken_channels,\r\n",
    "                debug=False)\r\n",
    "\r\n",
    "            freqs = np.zeros((500))\r\n",
    "            e_val, trace, freqs, pref, lab, ylab = corr.evaluation(\r\n",
    "                method=method,\r\n",
    "                arr1=np.array(dat['P_rad_hbc']['values']),\r\n",
    "                arr2=calculation,\r\n",
    "                id_1=ix_s, id_2=ix_t,\r\n",
    "                time_raw=dat['BoloSignal']['dimensions'],\r\n",
    "                freqs=freqs,\r\n",
    "                plot=False)\r\n",
    "            theta = e_val / alpha if method is not \\\r\n",
    "                'mean_deviation' else e_val\r\n",
    "            # print('\\t\\t\\\\\\ ', name, '...', combination, ':', theta)\r\n",
    "\r\n",
    "            # plot best combination\r\n",
    "            fig_location = '../results/COMBINATIONS/' + xpid + '/' + name + '_'\r\n",
    "            tpl.correlation_comb_plot(\r\n",
    "                arr1=np.array(dat['P_rad_hbc']['values'], dtype=np.float),\r\n",
    "                arr2=calculation, time=np.array(prio['time']),\r\n",
    "                method=method, pref=pref, lab=lab, ylab=ylab, loc=fig_location,\r\n",
    "                cell=combination,\r\n",
    "                trace=trace, phi=phi, freqs=freqs, beta=1.,  # beta,\r\n",
    "                alpha=alpha, theta=theta,\r\n",
    "                id_1=ix_s, id_2=ix_t)\r\n",
    "            # break\r\n",
    "            # break\r\n",
    "\r\n",
    "    # except Exception as e:\r\n",
    "    #     print('error', xpid, method, comb)\r\n",
    "    #     pass\r\n",
    "\r\n",
    "    if i != 0:\r\n",
    "        if xpid_old != xpid:\r\n",
    "            xpid_old = xpid\r\n",
    "            print('\\\\\\ ', xpid, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = p.subplots()\r\n",
    "ax.plot(np.nan_to_num(training_results['correlation']), c='k')\r\n",
    "ax.set_xlim(0, len(training_results['correlation']))\r\n",
    "ax.set_xlabel('combination [#]')\r\n",
    "ax.set_ylabel('quality [a.u.]')\r\n",
    "fig.set_size_inches(5., 2.5)\r\n",
    "fig.savefig(method + '_3_HBCm_combinations.pdf',\r\n",
    "            dpi=169.0, bbox_inches='tight')\r\n",
    "p.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pf)\n",
    "importlib.reload(corr)\n",
    "importlib.reload(sense)\n",
    "importlib.reload(tpl)\n",
    "importlib.reload(prad_calc)\n",
    "importlib.reload(mClass)\n",
    "\n",
    "base_URI = 'http://archive-webapi.ipp-hgw.mpg.de/'\n",
    "dat_URI = base_URI + 'Test/raw/W7XAnalysis/QSB_Bolometry/'\n",
    "loc = '//share.ipp-hgw.mpg.de/documents/pih/Documents/git/QSB_Bolometry/results/COMBINATIONS/'\n",
    "\n",
    "colors = cm.brg(np.linspace(.0, 1., 6))\n",
    "\n",
    "iterator = list(itertools.product(\n",
    "    dirs, # ['20180725.044', '20180809.013'],\n",
    "    methods, # ['coherence_fft'],\n",
    "    combs))  # dirs, methods, combs))\n",
    "\n",
    "for j in tqdm(range(len(iterator)), desc='combinations'):\n",
    "    # for j, entry in enumerate(iterator):\n",
    "    entry = iterator[j]\n",
    "    xpid, method, comb = entry\n",
    "    # print(entry)\n",
    "\n",
    "    if j == 0:\n",
    "        xpid_old = xpid\n",
    "        method_old = method\n",
    "        res_list = []\n",
    "        # print('\\\\\\ ', xpid, end=' ')\n",
    "        # print('\\\\\\ ', method, end=' ')\n",
    "\n",
    "    # if True:\n",
    "    try:\n",
    "        # load file of comb and method for xpid\n",
    "        # print('>> loading file:', method, comb)\n",
    "        file = loc + xpid + '/' + method + \\\n",
    "            '/' + comb + '/spectrum_analysis_' + method + '.json'\n",
    "        with open(file, 'r') as f:\n",
    "            training_results = json.load(f)\n",
    "        f.close()\n",
    "        res_list.append(np.array([\n",
    "            training_results['combinations'],\n",
    "            training_results['correlation']\n",
    "        ]))\n",
    "\n",
    "        if len(res_list) == 6:\n",
    "            fig = p.figure()\n",
    "            ax = fig.add_subplot(111)\n",
    "            fig_location = '../results/COMBINATIONS/' + xpid_old + '/'\n",
    "\n",
    "            for i, foo in enumerate(res_list):\n",
    "                N = 30  # int(np.shape(foo)[1] / 30.)\n",
    "                X = np.linspace(.0, 1., np.shape(foo)[1])\n",
    "                # X = np.linspace(1., np.shape(foo)[1] - 1, np.shape(foo)[1])\n",
    "                M, cam = combs[i].replace('_', ' ').split()\n",
    "                ax.plot(\n",
    "                    np.convolve(X, np.ones((N, )) / N, mode='valid'),\n",
    "                    np.convolve(foo[1], np.ones((N, )) / N, mode='valid'),\n",
    "                    c=colors[i], alpha=.75, label=cam + ', ' + M)\n",
    "\n",
    "            ax.set_yticklabels([''] * 10)\n",
    "            ax.set_xticklabels([''] * 10)\n",
    "\n",
    "            ax.set_xlim(.0, 1.)\n",
    "            ax.set_ylabel('quality [a.u.]')\n",
    "            ax.set_xlabel('combination [#]')\n",
    "            ax.legend(\n",
    "                loc='upper center', bbox_to_anchor=(.5, 1.3),\n",
    "                ncol=3, fancybox=True, shadow=False,\n",
    "                handletextpad=0.3, labelspacing=0.5, handlelength=1.)\n",
    "\n",
    "            fig.set_size_inches(5., 3.)\n",
    "            fig.savefig('../results/CURRENT/combinations_methods.pdf')\n",
    "            fig.savefig(\n",
    "                fig_location + method + '_' +\n",
    "                xpid_old.replace('.', '_') + '_combinations.pdf')\n",
    "            res_list = []\n",
    "            p.close('all')\n",
    "\n",
    "    except Exception as e:\n",
    "        print('error', xpid, method, comb)\n",
    "        pass\n",
    "\n",
    "    if j != 0:\n",
    "        if xpid_old != xpid:\n",
    "            xpid_old = xpid\n",
    "            # print('\\\\\\ ', xpid, end=' ')\n",
    "        if method_old != method:\n",
    "            method_old = method\n",
    "            # print('\\\\\\ ', method, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pf)\n",
    "importlib.reload(corr)\n",
    "importlib.reload(sense)\n",
    "importlib.reload(tpl)\n",
    "importlib.reload(prad_calc)\n",
    "importlib.reload(mClass)\n",
    "\n",
    "base_URI = 'http://archive-webapi.ipp-hgw.mpg.de/'\n",
    "dat_URI = base_URI + 'Test/raw/W7XAnalysis/QSB_Bolometry/'\n",
    "loc = '//share.ipp-hgw.mpg.de/documents/pih/Documents/git/QSB_Bolometry/results/COMBINATIONS/'\n",
    "\n",
    "colors = cm.brg(np.linspace(.0, 1., 3))\n",
    "markers = ['x', '^', 's']\n",
    "\n",
    "iterator = list(itertools.product(\n",
    "    ['20180725.044'],  # dirs, # ['20180725.044', '20180809.013'],\n",
    "    ['weighted_deviation'], # methods, # ['coherence_fft'],\n",
    "    ['3_HBCm', '5_HBCm', '7_HBCm']))\n",
    "\n",
    "for j in tqdm(range(len(iterator)), desc='combinations'):\n",
    "    # for j, entry in enumerate(iterator):\n",
    "    entry = iterator[j]\n",
    "    xpid, method, comb = entry\n",
    "\n",
    "    if j == 0:\n",
    "        xpid_old = xpid\n",
    "        method_old = method\n",
    "        res_list = []\n",
    "        # print('\\\\\\ ', xpid, end=' ')\n",
    "        # print('\\\\\\ ', method, end=' ')\n",
    "\n",
    "    if True:\n",
    "        # try:\n",
    "        # load file of comb and method for xpid\n",
    "        # print('>> loading file:', method, comb)\n",
    "        file = loc + xpid + '/' + method + \\\n",
    "            '/' + comb + '/spectrum_analysis_' + method + '.json'\n",
    "        with open(file, 'r') as f:\n",
    "            training_results = json.load(f)\n",
    "        f.close()\n",
    "        res_list.append(np.array([\n",
    "            training_results['av_sense_channels'],\n",
    "            training_results['av_sense_combination']\n",
    "        ]))\n",
    "\n",
    "        if len(res_list) == 3:\n",
    "            fig = p.figure()\n",
    "            ax = fig.add_subplot(111)\n",
    "            fig_location = '../results/COMBINATIONS/' + xpid_old + '/'\n",
    "\n",
    "            for i, foo in enumerate(res_list):\n",
    "                M, cam = ['3_HBCm', '5_HBCm', '7_HBCm'][i].replace('_', ' ').split()\n",
    "                ax.plot(foo[0], c=colors[i], alpha=.75, ls='-.',\n",
    "                        marker=markers[i], label=cam + ', ' + M)\n",
    "            \n",
    "            ax.set_xlim(.0, 31.)\n",
    "            ax.set_ylabel('quality [a.u.]')\n",
    "            ax.set_xlabel('channel [#]')\n",
    "            ax.legend(\n",
    "                loc='upper center', bbox_to_anchor=(.5, 1.3),\n",
    "                ncol=3, fancybox=True, shadow=False,\n",
    "                handletextpad=0.3, labelspacing=0.5, handlelength=1.)\n",
    "\n",
    "            fig.set_size_inches(5., 3.)\n",
    "            fig.savefig('../results/CURRENT/sensitivity_method.pdf')\n",
    "            fig.savefig(\n",
    "                fig_location + method + '_' +\n",
    "                xpid_old.replace('.', '_') + '_sensitivity_combs.pdf')\n",
    "            res_list = []\n",
    "            p.close('all')\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     print('error', xpid, method, comb)\n",
    "    #     pass\n",
    "\n",
    "    if j != 0:\n",
    "        if xpid_old != xpid:\n",
    "            xpid_old = xpid\n",
    "            # print('\\\\\\ ', xpid, end=' ')\n",
    "        if method_old != method:\n",
    "            method_old = method\n",
    "            # print('\\\\\\ ', method, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['weighted_deviation',\n 'self_correlation',\n 'mean_deviation',\n 'fft_solo',\n 'fft_and_convolve',\n 'fftconvolve_integrated',\n 'correlation',\n 'coherence_fft']"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "combinations: 100%|██████████| 156/156 [00:05<00:00, 28.51it/s]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pf)\r\n",
    "importlib.reload(corr)\r\n",
    "importlib.reload(sense)\r\n",
    "importlib.reload(tpl)\r\n",
    "importlib.reload(prad_calc)\r\n",
    "importlib.reload(mClass)\r\n",
    "\r\n",
    "base_URI = 'http://archive-webapi.ipp-hgw.mpg.de/'\r\n",
    "dat_URI = base_URI + 'Test/raw/W7XAnalysis/QSB_Bolometry/'\r\n",
    "loc = '//share.ipp-hgw.mpg.de/documents/pih/Documents/git/QSB_Bolometry/results/COMBINATIONS/'\r\n",
    "\r\n",
    "minor_radius = 0.5139\r\n",
    "\r\n",
    "colors = cm.brg(np.linspace(.0, 1., 3))\r\n",
    "markers = ['x', '^', 's']\r\n",
    "\r\n",
    "iterator = list(itertools.product(\r\n",
    "    ['weighted_deviation'],  # ['weighted_deviation'],\r\n",
    "    # ['3_HBCm', '5_HBCm', '7_HBCm'],  # combs,\r\n",
    "    ['3_VBC', '5_VBC', '7_VBC'],  # combs,\r\n",
    "    dirs))  # ['20180725.044']))\r\n",
    "\r\n",
    "loc_max = .0\r\n",
    "res_list, fin_list, errors = [], [], []\r\n",
    "for j in tqdm(range(len(iterator)), desc='combinations'):\r\n",
    "    # for j, entry in enumerate(iterator):\r\n",
    "    entry = iterator[j]\r\n",
    "    method, comb, xpid = entry\r\n",
    "\r\n",
    "    if True:\r\n",
    "        # try:\r\n",
    "        # load file of comb and method for xpid\r\n",
    "        # print('>> loading file:', method, comb)\r\n",
    "        file = loc + xpid + '/' + method + \\\r\n",
    "            '/' + comb + '/spectrum_analysis_' + method + '.json'\r\n",
    "        with open(file, 'r') as f:\r\n",
    "            training_results = json.load(f)\r\n",
    "        f.close()\r\n",
    "        res_list.append(np.array([\r\n",
    "            training_results['av_sense_channels'],\r\n",
    "            training_results['av_sense_combination']\r\n",
    "        ]))\r\n",
    "\r\n",
    "        if len(res_list) == 52:\r\n",
    "            res_list = np.array(res_list)\r\n",
    "            foo = res_list.reshape(2, 52, 128)\r\n",
    "            res_list = []\r\n",
    "\r\n",
    "            bar = np.percentile(foo[1], 97.5, axis=(0))\r\n",
    "            fin_list.append(bar)\r\n",
    "            loc_max = np.nansum(bar) / np.shape(np.unique(\r\n",
    "                bar))[0] if np.nansum(bar) / np.shape(np.unique(\r\n",
    "                    bar))[0] > loc_max else loc_max\r\n",
    "\r\n",
    "            E = np.zeros((128))\r\n",
    "            for c in range(128):\r\n",
    "                a, b = \\\r\n",
    "                    np.percentile(foo[1, :, c], 85.), \\\r\n",
    "                    np.percentile(foo[1, :, c], 97.5)\r\n",
    "                E[c] = np.std(foo[1, :, c][\r\n",
    "                    np.where((a < foo[1, :, c]) & (foo[1, :, c] < b))[0]])\r\n",
    "            errors.append(E)\r\n",
    "\r\n",
    "        if len(fin_list) == 3:\r\n",
    "            fig = p.figure()\r\n",
    "            ax = fig.add_subplot(111)\r\n",
    "            ar = ax.twiny()\r\n",
    "\r\n",
    "            k = 0\r\n",
    "            for X, E in zip(fin_list, errors):\r\n",
    "                # M, cam = ['3_HBCm', '5_HBCm', '7_HBCm'][k].replace(\r\n",
    "                #     '_', ' ').split()\r\n",
    "                M, cam = ['3_VBC', '5_VBC', '7_VBC'][k].replace(\r\n",
    "                    '_', ' ').split()\r\n",
    "            \r\n",
    "                no_nans = np.argwhere(X == X)\r\n",
    "                channels = [x for x in np.unique(no_nans)]\r\n",
    "                NChannels = np.linspace(\r\n",
    "                    .0, len(channels) - 1, len(channels))\r\n",
    "\r\n",
    "                x = X[channels]\r\n",
    "                e = E[channels]\r\n",
    "\r\n",
    "                R = []\r\n",
    "                for c, channel in enumerate(channels):\r\n",
    "                    R.append(info['radius']['reff'][channel] / minor_radius)\r\n",
    "\r\n",
    "                index_list = np.argsort(np.array(R))\r\n",
    "                sort_channels = np.array(channels)[index_list]\r\n",
    "                sort_R = np.array(R)[index_list]\r\n",
    "\r\n",
    "                if ('fft' in method) or (method == 'correlation'):\r\n",
    "                    X = X / loc_max\r\n",
    "                    E = E / loc_max\r\n",
    "\r\n",
    "                ax.errorbar(\r\n",
    "                    np.linspace(0, 127, 128), X, yerr=E,\r\n",
    "                    # NChannels, x, yerr=e,\r\n",
    "                    c=colors[k], alpha=.75, ls='-.',\r\n",
    "                    marker=markers[k], label=cam + ', ' + M)\r\n",
    "                k += 1\r\n",
    "            fin_list = []\r\n",
    "            errors = []\r\n",
    "\r\n",
    "            for axis in [ax, ar]:\r\n",
    "                axis.set_xlim(np.min(channels), np.max(channels))\r\n",
    "            tick_locs = ax.get_xticks()\r\n",
    "            N = int(np.ceil(\r\n",
    "                np.shape(channels)[0] / np.shape(tick_locs)[0]))\r\n",
    "\r\n",
    "            # ar.set_xticks(channels[::N])\r\n",
    "            ar.set_xticklabels([str(round(r, 2)) for r in sort_R[::N]])\r\n",
    "            ar.set_xlabel('radius [r$_{a}$]')\r\n",
    "\r\n",
    "            ax.set_ylabel('quality [a.u.]')\r\n",
    "            ax.set_xlabel('channel [#]')\r\n",
    "            ax.legend()\r\n",
    "            #     loc='upper center', bbox_to_anchor=(.5, 1.2),\r\n",
    "            #     ncol=3, fancybox=True, shadow=False,\r\n",
    "            #     handletextpad=0.3, labelspacing=0.5, handlelength=1.)\r\n",
    "\r\n",
    "            fig.set_size_inches(5., 3.)\r\n",
    "            fig.savefig('../results/CURRENT/sensitivity_combs.pdf')\r\n",
    "            fig_location = '../results/COMBINATIONS/'\r\n",
    "            fig.savefig(\r\n",
    "                fig_location + method + '_sensitivity_combs_' + cam + '.pdf')\r\n",
    "            p.close('all')\r\n",
    "\r\n",
    "    # except Exception as e:\r\n",
    "    #     print('error', xpid, method, comb)\r\n",
    "    #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_results = {\r\n",
    "    'xpids': dirs,\r\n",
    "    'data': {\r\n",
    "    }\r\n",
    "}\r\n",
    "\r\n",
    "xpids = np.array(dirs)\r\n",
    "iterator = list(itertools.product(\r\n",
    "    methods,  # ['weighted_deviation'],\r\n",
    "    combs,\r\n",
    "    dirs))  # [:100]\r\n",
    "for i in tqdm(range(len(iterator)), desc='combinations'):\r\n",
    "    method, comb, xpid = iterator[i]\r\n",
    "    if i == 0:\r\n",
    "        old_comb, old_method = comb, method\r\n",
    "\r\n",
    "    if method != old_method or i == 0:\r\n",
    "        full_results['data'][method] = {}\r\n",
    "\r\n",
    "    if comb != old_comb or i == 0:\r\n",
    "        full_results['data'][method][comb] = {\r\n",
    "            'av_sense_channels': None,\r\n",
    "            'av_sense_combination': None}\r\n",
    "        av_channels = np.zeros((128, len(dirs)))\r\n",
    "        av_combination = np.zeros((128, len(dirs)))\r\n",
    "\r\n",
    "    file = loc + xpid + '/' + method + \\\r\n",
    "        '/' + comb + '/spectrum_analysis_' + method + '.json'\r\n",
    "    with open(file, 'r') as f:\r\n",
    "        dat = json.load(f)\r\n",
    "    f.close()\r\n",
    "\r\n",
    "    j = np.where(xpids == xpid)[0][0]\r\n",
    "    av_channels[:, j] = dat['av_sense_channels']\r\n",
    "    av_combination[:, j] = dat['av_sense_combination']\r\n",
    "\r\n",
    "    if ((i != len(iterator) - 1) and (\r\n",
    "            comb != iterator[i + 1][1])) or (\r\n",
    "            i == len(iterator) - 1):\r\n",
    "        full_results['data'][method][comb][\r\n",
    "            'av_sense_channels'] = av_channels\r\n",
    "        full_results['data'][method][comb][\r\n",
    "            'av_sense_combination'] = av_combination\r\n",
    "\r\n",
    "    if i != 0:\r\n",
    "        if method != old_method:\r\n",
    "            old_method = method\r\n",
    "        if comb != old_comb:\r\n",
    "            old_comb = comb\r\n",
    "\r\n",
    "np.save(\r\n",
    "    '../results/COMBINATIONS/training_results.npy',\r\n",
    "    full_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results = np.load('../results/COMBINATIONS/training_results.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecrh_power = []\n",
    "ne = []\n",
    "Te_core = []\n",
    "Te_out = []\n",
    "prad = []\n",
    "frad = []\n",
    "\n",
    "for i in tqdm(range(len(full_results['xpids'])), desc='programs'):\n",
    "    program = full_results['xpids'][i]\n",
    "    program_info, req = api.xpid_info(program=program)\n",
    "    t0 = program_info['programs'][0]['trigger']['1'][0]  # in ns\n",
    "    t4 = program_info['programs'][0]['trigger']['4'][0]  # in ns\n",
    "\n",
    "    fr, rad, ecrh = radfrac.radiational_frac(program=program)\n",
    "\n",
    "    try:\n",
    "        ecrh_power.append(np.array(ecrh['values']))\n",
    "    except Exception as e:\n",
    "        ne.append(np.array([np.nan]))\n",
    "\n",
    "    try:\n",
    "        prad.append(np.array(rad['values']))\n",
    "        if np.max(prad[-1]) > 10.:\n",
    "            prad.append(np.array([np.nan]))\n",
    "    except Exception as e:\n",
    "        prad.append(np.array([np.nan]))\n",
    "\n",
    "    try:\n",
    "        frad.append(np.array(fr[1])[\n",
    "            ~np.isnan(np.array(fr[1]))])\n",
    "    except Exception as e:\n",
    "        frad.append(np.array([np.nan]))\n",
    "\n",
    "    try:\n",
    "        ne.append(np.array(api.download_single(\n",
    "            api.download_link(name='n_e lint'),\n",
    "            program_info=None, filter=None,\n",
    "            start_POSIX=t0, stop_POSIX=t4)['values']))\n",
    "    except Exception:\n",
    "        ne.append(np.array([np.nan]))\n",
    "\n",
    "    try:\n",
    "        Te_core.append(np.array(api.download_single(\n",
    "            api.download_link(name='T_e ECE core'),\n",
    "            program_info=None, filter=None,\n",
    "            start_POSIX=t0, stop_POSIX=t4)['values']))\n",
    "    except Exception as e:\n",
    "        Te_core.append(np.array([np.nan]))\n",
    "\n",
    "    try:\n",
    "        Te_out.append(np.array(api.download_single(\n",
    "            api.download_link(name='T_e ECE out'),\n",
    "            program_info=None, filter=None,\n",
    "            start_POSIX=t0, stop_POSIX=t4)['values']))\n",
    "    except Exception as e:\n",
    "        Te_out.append(np.array([np.nan]))\n",
    "\n",
    "proginfo_training = {\n",
    "    'ECRH': ecrh_power,\n",
    "    'ne lint': ne,\n",
    "    'Te core': Te_core,\n",
    "    'Te out': Te_out,\n",
    "    'prad': prad,\n",
    "    'frad': frad}\n",
    "np.save('../results/COMBINATIONS/proginfo_training_results.npy', proginfo_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proginfo_training = np.load('../results/COMBINATIONS/proginfo_training_results.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entry = 'av_sense_channels'\n",
    "cams = ['HBCm', 'VBC']\n",
    "param_list = [\n",
    "    ['ECRH', 'ECRH [MW]', 1.],\n",
    "    ['ne lint', 'n$_{e}$ int. [10$^{19}$ m$^{-3}$]', 1.e19],\n",
    "    ['Te core', 'T$_{e}$ [keV]', 1.],\n",
    "    ['Te out', 'T$_{e}$ [keV]', 1.],\n",
    "    ['prad', 'P$_{rad}$ [MW]', 1.],\n",
    "    ['frad', 'f$_{rad}$ [a.u.]', 1.]]\n",
    "iterator = list(itertools.product(cams, methods, param_list))\n",
    "\n",
    "for j in tqdm(range(len(iterator)), desc='combinations'):\n",
    "    cam, method, param_entry = iterator[j]\n",
    "    param, cbarax, f = param_entry\n",
    "\n",
    "    channels = info['channels']['eChannels'][cam]\n",
    "    camrange = [np.min(channels), np.max(channels)]\n",
    "    dataM = full_results['data'][method]\n",
    "\n",
    "    full_sense = []\n",
    "    for comb in combs:\n",
    "        if (cam not in comb) or (\n",
    "                isinstance(dataM[comb][entry], None.__class__)):\n",
    "            continue\n",
    "\n",
    "        for trainingXP in dataM[comb][entry].transpose():\n",
    "            full_sense.append(trainingXP)\n",
    "    full_sense = np.array(full_sense).transpose()\n",
    "\n",
    "    no_nans = np.argwhere(full_sense == full_sense)\n",
    "    channels = [x for x in np.unique(no_nans[:, 0])]\n",
    "\n",
    "    N = 25  # number of bins\n",
    "    bins_y  = np.linspace(\n",
    "        np.min(np.nan_to_num(full_sense, np.inf)),\n",
    "        np.max(np.nan_to_num(full_sense, -np.inf)),\n",
    "        N)\n",
    "\n",
    "    # XP data, devide as well\n",
    "    parameter = proginfo_training[param]\n",
    "\n",
    "    contour = np.zeros((N, np.shape(channels)[0]))\n",
    "    ticks = np.zeros((N, np.shape(channels)[0]))\n",
    "    for c, channel in enumerate(channels):\n",
    "        diggi = np.digitize(full_sense[channel], bins_y)\n",
    "\n",
    "        for xpid in range(N):\n",
    "            biny = diggi[xpid] - 1\n",
    "            if (np.shape(parameter[biny])[0]) > 0 and (\n",
    "                    parameter[biny][0] != .0) and (~np.isnan(parameter[biny][0])):\n",
    "                contour[biny, c] += np.quantile(\n",
    "                    parameter[biny] / f, .95)\n",
    "                ticks[biny, c] += 1.\n",
    "\n",
    "    fig = p.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    ar = ax.twiny()\n",
    "\n",
    "    minor_radius = 0.5139\n",
    "    NChannels = np.linspace(\n",
    "        .0, len(channels) - 1, len(channels))\n",
    "\n",
    "    R = []\n",
    "    for c, channel in enumerate(channels):\n",
    "        R.append(info['radius']['reff'][channel] / minor_radius)\n",
    "\n",
    "    index_list = np.argsort(np.array(R))\n",
    "    sort_channels = np.array(channels)[index_list]\n",
    "    sort_contour = contour[:, index_list]\n",
    "    sort_ticks = ticks[:, index_list]\n",
    "    sort_R = np.array(R)[index_list]\n",
    "\n",
    "    for axis in [ax, ar]:\n",
    "        # axis.set_xlim(np.min(channels), np.max(channels))\n",
    "        axis.set_xlim(np.min(NChannels), np.max(NChannels))\n",
    "\n",
    "    # xx, yy = np.meshgrid(channels, bins_y)\n",
    "    xx, yy = np.meshgrid(NChannels, bins_y)\n",
    "    cs = ax.contourf(\n",
    "        xx, yy,\n",
    "        np.nan_to_num(contour / ticks),\n",
    "        20, cmap='plasma',\n",
    "        alpha=1.)\n",
    "\n",
    "    cax = fig.add_axes([0.98, 0.13, 0.03, 0.74])\n",
    "    cbar = fig.colorbar(cs, orientation='vertical', cax=cax)\n",
    "\n",
    "    tick_locs = ax.get_xticks()\n",
    "    N = int(np.ceil(\n",
    "        # np.shape(channels)[0] / np.shape(tick_locs)[0]))\n",
    "        np.shape(NChannels)[0] / np.shape(tick_locs)[0]))\n",
    "\n",
    "    # ar.set_xticks(channels[::N])\n",
    "    ar.set_xticks(NChannels[::N])\n",
    "    # ar.set_xticklabels([str(round(r, 2)) for r in R[::N]])\n",
    "    ar.set_xticklabels([str(round(r, 2)) for r in sort_R[::N]])\n",
    "\n",
    "    ar.set_xlabel('radius [r$_{a}$]')\n",
    "    ax.set_xlabel('channel [#]')\n",
    "    ax.set_ylabel('quality [a.u.]')\n",
    "    cbar.ax.set_ylabel(cbarax)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.set_size_inches(5., 3.)\n",
    "\n",
    "    pf.fig_current_save('sensitivity_parameters', fig)\n",
    "    fig_location = '../results/COMBINATIONS/' + method + \\\n",
    "        '_sensitivity_params_' + param.replace(' ', '_') + '_' + cam + '.pdf'\n",
    "    fig.savefig(fig_location)\n",
    "    p.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = p.figure()\r\n",
    "ax = fig.add_subplot()\r\n",
    "ar = ax.twiny()\r\n",
    "\r\n",
    "minor_radius = 0.5139\r\n",
    "NChannels = np.linspace(\r\n",
    "    .0, len(channels) - 1, len(channels))\r\n",
    "\r\n",
    "R = []\r\n",
    "for c, channel in enumerate(channels):\r\n",
    "    R.append(info['radius']['reff'][channel] / minor_radius)\r\n",
    "\r\n",
    "index_list = np.argsort(np.array(R))\r\n",
    "sort_channels = np.array(channels)[index_list]\r\n",
    "sort_contour = contour[:, index_list]\r\n",
    "sort_ticks = ticks[:, index_list]\r\n",
    "sort_R = np.array(R)[index_list]\r\n",
    "\r\n",
    "for axis in [ax, ar]:\r\n",
    "    # axis.set_xlim(np.min(channels), np.max(channels))\r\n",
    "    axis.set_xlim(np.min(NChannels), np.max(NChannels))\r\n",
    "\r\n",
    "# xx, yy = np.meshgrid(channels, bins_y)\r\n",
    "xx, yy = np.meshgrid(NChannels, bins_y)\r\n",
    "cs = ax.contourf(\r\n",
    "    xx, yy,\r\n",
    "    np.nan_to_num(contour / ticks),\r\n",
    "    20, cmap='plasma',\r\n",
    "    alpha=1.)\r\n",
    "\r\n",
    "cax = fig.add_axes([0.98, 0.13, 0.03, 0.74])\r\n",
    "cbar = fig.colorbar(cs, orientation='vertical', cax=cax)\r\n",
    "\r\n",
    "tick_locs = ax.get_xticks()\r\n",
    "N = int(np.ceil(\r\n",
    "    # np.shape(channels)[0] / np.shape(tick_locs)[0]))\r\n",
    "    np.shape(NChannels)[0] / np.shape(tick_locs)[0]))\r\n",
    "\r\n",
    "# ar.set_xticks(channels[::N])\r\n",
    "ar.set_xticks(NChannels[::N])\r\n",
    "# ar.set_xticklabels([str(round(r, 2)) for r in R[::N]])\r\n",
    "ar.set_xticklabels([str(round(r, 2)) for r in sort_R[::N]])\r\n",
    "\r\n",
    "ar.set_xlabel('radius [r$_{a}$]')\r\n",
    "ax.set_xlabel('channel [#]')\r\n",
    "ax.set_ylabel('quality [a.u.]')\r\n",
    "cbar.ax.set_ylabel(cbarax)\r\n",
    "\r\n",
    "fig.tight_layout()\r\n",
    "fig.set_size_inches(5., 3.)\r\n",
    "\r\n",
    "pf.fig_current_save('sensitivity_parameters', fig)\r\n",
    "fig_location = '../results/COMBINATIONS/' + method + \\\r\n",
    "    '_sensitivity_params_' + param.replace(' ', '_') + '_' + cam + '.pdf'\r\n",
    "fig.savefig(fig_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "name": "python374jvsc74a57bd02bd2964364db3b719c42815f72d108a73b2f2b078d4935488ba58600ae9e429a"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}